name_of_project: 'Mayotte'
num_cores: 1 # How many cores would you like to use for travel time calculations? (it will increase memory cost)
vel_model_ver: 1 ## Which travel time version to save when running calculate travel times

## Note, when running continuous days processing a number of parameters are also set in process_config

latitude_range: [18.8, 20.3] # Latitude range of the region that will be processed
longitude_range: [-156.1, -154.7] # Longitude range of the region that will be processed
depth_range: [-40000, 5000] # Note: depths are in meters, positive above sea level, negative below sea level, and 'increasing' depth means going from deep to shallow.
time_range: # This sets up the Catalog and Pick files to have these years initialized
  start: '2018-01-01'
  end: '2023-01-01'

client : 'IRIS'
network: 'HV'
pre_load_stations: False # If True, then skip download stations during make_initial_files.py; instead, stations.npz is assumed to already exist with locs and stas as the two fields.
use_physics_informed: False ## If true, must run the "build" and "train" scripts seperately for the travel times and load a 3D (or 1D) velocity model

degree_padding: 0.25 # This region is appended to the lat_range and lon_range values above, and is used as a `padding' region, where we compute travel times, and simulate events in this region, yet train to predict zero for all labels in this area. This way, sources just outside the domain of interest arn't falsely mis-located inside the region (since the model learns what `exterior' events look like, to some extent).
number_of_grids: 5 # Number of distinct spatial graphs to create (this reduced slight bias that can result from only using one spatial graph)
number_of_spatial_nodes: 500 # Number of nodes per spatial graph

load_initial_files: [False]
use_pretrained_model: [None]

velocity_model:
  Depths: [-40000, -35000, -30000, -25000, -20000, -15000, -10000, -5000, 0, 5000]
  Vp: [8200, 8200, 8150, 8100, 8050, 7400, 6800, 6100, 2900, 2900]
  Vs: [4700, 4700, 4650, 4600, 4600, 4200, 3800, 3400, 1800, 1800]

### ASSEMBLE NETWORK DATA ###
with_density: False
use_spherical: False ## Should only set to true if travel time model also has spherical projection (to be added soon)
depth_importance_weighting_value_for_spatial_graphs: 2.5 # up scale the depth importance of node positions when creating spatial graph if using a large horizontally extended domain
fix_nominal_depth: True
number_of_update_steps: 5000

### TRAVEL TIMES ###
## These are the elevation ranges over which stations might vary
## we compute travel times for a range of reciever elevations
depth_steps:
  min_elevation: -500 # meters
  max_elevation: 4000 # meters
  elevation_step: 150 # meters

# Can increase or decrease these as needed
dx: 500.0 # Cartesian distance between nodes in FMM computation
d_deg: 0.005 # Degree distance between saved interpolation query points
dx_depth: 500.0 # Depth distance between nodes in FMM computation and saved query points

save_dense_travel_time_data: False # Save the dense travel times (only necessary if not training travel time neural network)
train_travel_time_neural_network: True # Fit a travel time neural network to the computed travel times
use_relative_1d_profile: True # If False, the 1D profile is treated as absolute; if True, the 1D profile is shifted so zero depth occurs at each stations elevation
using_3D: False # Not fully implemented yet, must adjust travel time calculations and load 3d travel time neural network
using_1D: True

## Graph params
k_sta_edges: 8 # or 10 are reasonable choices
k_spc_edges: 15
k_time_edges: 10
t_win: 10.0 ## This is the time window over which predictions are made. Shouldn't be changed for now.
## Note that right now, this shouldn't change, as the GNN definitions also assume this is 10 s.

## Use subgraph
use_subgraph: False
max_deg_offset: 1.5
k_nearest_pairs: 30

## Additional training params
device: 'cuda' # or 'cpu'
max_number_pick_association_labels_per_sample: 1500 # Max number of picks to compute associations for during training 
## (cuda RAM can run out for very large numbers of input picks in a single window during training at association prediction step). 
## This does not effect the input picks, just the ones we predict association labels for
make_visualize_predictions: True # Plot example predictions during training (note: creates a lot of files currently)
