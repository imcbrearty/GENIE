
## Training synthetic data parameters

## Note that there are some combinations of parameters for a given application that will result in essentially
## "all zero" labels, and so the model will not be able to learn anything. This mainly happens when the number of
## simulated events, and the total extent of their moveouts (dist_range) do not allow most events to be detectable
## by stations. By checking the output file in GNN_TrainedModels/"project_name"_output_ver_1.txt, you can monitor
## the "trgts" variable, which is the sum over the batch of the four labels of source predictions on
## x_query_static, x_query, p_associations, s_associations. If these values are all zero, it will not learn;
## a good area seems to be between ~5 - 30. Over time, the model should learn to roughly match these targets
## in the "preds" column. If it does, it is generally well trained. Using preferential_sampling = True also
## concentrates the sampled inputs around times of active sources, which increases the positive label rate.

## The synthetic data can also be inspected, as it's the last output of generate_synthetic_data,
## where data[0][:,0] are pick times, data[0][:,1] are pick indices (w.r.t. the station.npz file ordering)
## data[0][:,2] is the phase type. Also, data[1] are the sources, and data[2] are the "active source" indices 
## (those with enough picks to be detectable). The theoretical moveouts can be computed with:
## trv(torch.Tensor(locs).to(device), torch.Tensor(data[1][data[2]]).to(device)).cpu().detach().numpy() + data[1][data[2]][:,3].reshape(-1,1,1)

## The kernel values should scale with the size of the region; e.g., they have to be big enough 
## such that they are proportional to the average grid spacing, but too large that they saturate across all of space.
## In process_config, the sp_win and tc_win clustering values, and d_win relocation window size, should also somewhat
## scale with these values.

## File versions
template_ver : 1 # source spatial grid version
vel_model_ver : 1 # velocity model version
n_ver : 1 # model save version

## Training params
n_batch: 30 # 75 # batch size
n_epochs: 15001 # Number of update steps (not technically epochs)
n_spc_query: 4500 # Number of src queries per sample
n_src_query: 300 # Number of src-arrival queries per sample

## Prediction params
## These parameters should somewhat scale with the size of the application
kernel_sig_t: 5.0 # Kernel to embed arrival time - theoretical time misfit (s)
src_t_kernel: 6.5 # Kernel of origin time label (s)
src_t_arv_kernel: 6.5 # Kernel for arrival association time label (s)
src_x_kernel: 15000. # Kernel for source label, horizontal distance (m)
src_x_arv_kernel: 15000. # Kernel for arrival-source association label, horizontal distance (m)
src_depth_kernel: 15000. # Kernel of source label in Cartesian projection, vertical distance (m)

## Training params list 2
spc_random : 15000 # Spatial scale to randomly remove true picks from stations ontop of threshold distance per event
sig_t : 0.03 # Percent of travel time error on pick times (e.g., 3%)
spc_thresh_rand : 15000 # Spatial scale to randomly shift threshold distance of P and S waves per event
min_sta_arrival : 6 # Min number of unique stations required for a positive label source event
coda_rate : 0.035 # Percent of picks with false coda picks (e.g., 3.5%)
coda_win : [0, 20.0] # Window that code picks can occur over (e.g., 25 s)
max_num_spikes : 20 # Number of possible network wide spikes per window T of synthetic data
spike_time_spread : 0.15 # The temporal spread of the network wide spikes
s_extra : 0.0 # If this is non-zero, it can increase (or decrease) the total rate of missed s waves compared to p waves
use_stable_association_labels : True # This flag only allows positive association labels that occur within thresh_noise_max ratio of true travel time
thresh_noise_max : 2.5 # ratio of sig_t*travel time considered excess noise when using use_stable_association_labels
min_misfit_allowed: 1.0 # The minimum time (in seconds), beneath which, differences in theoretical and observed arrival times for true sources have positive association labels (the upper limit set by ratio of travel times, given by thresh_noise_max)
total_bias: 0.03 ## Total possible bias on travel times (uniform across stations) for each theoretical moveout curve (helps build in robustness to systematic differences between assumed and true velocity models). Default is 3%
# training_params_2 = [spc_random, sig_t, spc_thresh_rand, min_sta_arrival, coda_rate, coda_win, max_num_spikes, spike_time_spread, s_extra, use_stable_association_labels, thresh_noise_max]

## Training params list 3
dist_range : [15000, 400000] # This is the distance range over which to simulate theoretical moveouts of picks per event. Should scale with domain size.
max_rate_events : 100 # 350 # 450 # Average rate of events per T window of time (e.g., T = 3 hrs, so 500*8 = 4000 events/day)
max_miss_events : 225 # 225 # 325 # Average rate of missed picks per station per T window of time. Note: this parameter does not work quite as intended; it is overwritten by miss_pick_fraction below
max_false_events : 125 # 250 # 250 # Average rate of false picks per station per T window of time (e.g., T = 3 hrs, so 250*8 = 2000 false picks / station / day)
miss_pick_fraction : [0.1, 0.5] # False # Average ratio of missed picks (if this is not False, it re-scales the miss pick rate to this ratio of true picks)
T : 10800 # Time window to simualate synthetic data. More variability occurs per-batch, when T is longer. Note that this parameter trades off with max_rate_events, max_miss_events and max_false_events.
dt : 30 # Time resolution to allow synthetic data parameters to vary in time, during the T window of synthetic data
tscale : 3600 # Time scale that synthetic data parameters vary in time, during the T window of synthetic data. E.g., the smoothness that synthetic data parameters vary.
n_sta_range : [0.35, 1.0] # The ratio of possible stations from full set considered per station graph input to GNN. Note that n_sta_range[0]*locs.shape[0] must be >= the number of station edges chosen (k_sta_edges)
use_sources : False
use_full_network : False
fixed_subnetworks : True ## If True, this uses realistic sets of stations available from the data saved in Picks. This can improve the model performance on real data (note: pick indices of each station must be saved in P[:,1] of pick files).
use_preferential_sampling : True ## This concentrates more of the samples around times of known events, so labels arn't too sparse (e.g., trgt values in "project_name"_output.txt in GNN_TrainedNModels should not be all zeros)
use_extra_nearby_moveouts : True ## This up-samples the amount of sources with moveouts only to nearby stations (e.g., it uses ~half of the distance range set in dist_range for 50% of events)
use_shallow_sources : False

## Use reference density for source distribution
use_reference_spatial_density: False ## If True, must store reference sources in "Calibration/"yr"/"project_name"_reference_2023_1_3_ver_1.npz with field "srcs_ref"
spatial_sigma: 20000.0 ## The amount of spatial smoothing to the reference catalog
min_magnitude_ref: 1.5 ## Min magnitude to consider for reference catalog
percentile_threshold_ref: 0.00001 ## Take all areas of > kernel Gaussian estimation probability as the "uniform" area to sample sources within
n_reference_clusters: 10000 ## The amount of "quasi-uniiform" nodes to obtain for representing the source catalog distribution
n_frac_reference_catalog: 0.8 ## The amount of sources to simulate from the reference catalog coordinates compared to background


## Extra dataset parameters
build_training_data : False ## Pre-build training data (rather than building inside training loop)
load_training_data : False ## Load the pre-built training data during training
path_to_data : '' ## Specify absolute path to the training data folder
n_ver_training_data : 1 ## Training data version
n_batches_per_job : 250 ## Number of batches of data to create per job array index when building dataset
refresh_subnetworks : True ## If true, always reload the subnetworks to be updated with subnetworks available in current pick files

# training_params_3 = [n_batch, dist_range, max_rate_events, max_miss_events, max_false_events, miss_pick_fraction, T, dt, tscale, n_sta_range, use_sources, use_full_network, fixed_subnetworks, use_preferential_sampling, use_shallow_sources]
