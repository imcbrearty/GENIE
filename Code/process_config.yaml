## Processing
n_ver_load: 1
n_step_load: 15000
n_save_ver: 1
n_ver_picks: 1

template_ver: 1
vel_model_ver: 1
process_days_ver: 1 
## Put the list of days you want to process in file $ProjectName$_process_days_list_ver_%d.txt

## Note: the default settings have some redundance and averaging built in, but speeds can be improved in a few ways.
## To speed up processing, can increase step (e.g. step: 5 - 10), and use only one grid during location refinement step (use_only_one_grid: True)
## To have higher accuracy, decrease step (e.g., step: 2), and average over all grids (use_only_one_grid: False)

## Additional ways to speed up code are decreasing n_rand_query to loose some spatial resolution, and also increase thresh to reduce number of sources,
## which reduces post-processing costs. The simplest way to process long intervals of time is to call process_continuous_days.py on many different
## input days (specified by the system argument argv[1] passed to the script: e.g., python process_continuous_days.py $n$ for any integer $n$, 
## which selects the nth day given in $ProjectName$_process_days_list_ver_1.txt), so that many parallel days can be submitted to run on individual cores.

## Note: for more accurate processing, set step = 2.0, and use_only_one_grid = False.
## It is faster when using the default step = 5.0, and use_only_one_grid = True.

offset_increment: 500 ## This only effects the choice of pick files used when submitting multiple jobs such as jobarrays
n_rand_query: 112000 ## This is the number of spatial points to re-locate initial source locations with higher resolution (an efficient implementation)
n_query_grid: 10000 ## This is the number of spatial points to save initial space-time continuous outputs over

thresh: 0.3 # Threshold to declare detection (previously, ~0.15 - 0.2 was effective, but recent changes to synthetic data tend to make higher thresholds also effective (e.g., even ~0.5 - 0.8 may be usable))
thresh_assoc: 0.3 # Threshold to declare src-arrival association

# spr: 1 # Sampling rate to save temporal predictions (may still cause some issues if this is changed from 1 s for now)
# tc_win: 5.0 # Temporal window (s) to link events in Local Marching
# sp_win: 15000.0 # Distance (m) to link events in Local Marching. Generally both of these on the order of training kernel sizes

break_win: 15.0 # Temporal window to find disjoint groups of sources, 
## so can run Local Marching without memory issues.
spr_picks: 1 # Assumed sampling rate of picks (e.g., spr_picks = 1 means absolute time, spr_picks = 100 means 100 Hz sampling rate). Note, previous default was spr_picks = 100.
## (can be 1 if absolute times are used for pick time values)

# d_win: 0.25 ## Lat and lon window to re-locate initial source detetections with refined sampling over (should be proportional to the label kernel widths)
# d_win_depth: 10000.0 ## Depth window to re-locate initial source detetections with refined sampling over (should be proportional to the label kernel widths)
# dx_depth: 50.0 ## Depth resolution to locate events with travel time based re-location (unused, if using differential evolution location)

step_size: 'full' ## 'full' or 'partial' (partial uses 3x overlap and stacking, with increased computational cost)
# step: 5.0 ## (For more accurate processing, choose 2 s; more efficient processing choose 5 s) Temporal step size to predict source outputs over, and stack overlapping portions (must be less than default source window prediction is 10 s)
# step_abs: 1.0 ## Time resolution to save the initial space-time predictions. Don't change this for now.

use_quality_check: True ## If True, check all associated picks and set a maximum allowed relative error after obtaining initial location
max_relative_error: 0.2 ## 0.15 corresponds to 15% maximum relative error allowed
min_time_buffer: 1.5 ## Uses this time (seconds) as a minimum residual time, beneath which, the relative error criterion is ignored (i.e., an associated pick is removed if both the relative error > max_relative_error and the residual > min_time_buffer)

cost_value: 2.5 # If use expanded competitve assignment, then this is the fixed cost applied per source
## when optimizing joint source-arrival assignments between nearby sources. The value is in terms of the 
## `sum' over the predicted source-arrival assignment for each pick. Ideally could make this number more
## adpative, potentially with number of stations or number of possible observing picks for each event. 

device: 'cuda' ## This can run on cuda, but it can also be faster to run ~100s of independent jobs
## on different CPU's to process 100's of days at once, instead of using a few GPU's

use_only_one_grid: True # (Use False for more accurate processing; for more efficient processing choose True. Accuracy is gained from averaging prediction over multiple spatial grids)
compute_magnitudes: False # Uses local magnitude and will be un-calibrated by default, or can calibrate for a particular study site
min_log_amplitude_val: -2 # If computing magnitudes, then this is the minimum amplitude (in log domain) considered (this helps avoid biasing magnitudes by amplitude measurements of only noise)
## Note: if using counts, -2 is reasonable for min_log_amplitude_val, but if using physical units of velocity/displacement, it will likely have to be much lower.

parallel_processing: False ## (not implemented yet) Will parallelize the looping of the forward pass in time over available cpus
process_known_events: False ## Only process times of known events in a reference catalog (default is USGS)
load_prebuilt_sampling_grid: True ## Use the pre-built spatial grid to save initial source detections on (note: if False, we re-make the spatial grid to save initial source detections on each time)
use_expanded_competitive_assignment: True ## This is advised, but the code is complex to avoid both memory issues and handling nearby or overlapping sources
use_differential_evolution_location: True # otherwise use particle swarm to locate, which tends to converge less well (especially in depth)

## Minimum requirements for keeping event after associations
min_required_picks: 5 ## Minimum required picks per event (set this or min_required_sta to False to not enforce minimum pick requirements)
min_required_sta: 5 ## Minimum required stations per event (set this or min_required_picks to False to not enforce minimum pick requirements)
